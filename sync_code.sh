#!/bin/bash

echo "ğŸ”„ åŒæ­¥ä»£ç åˆ°æœåŠ¡å™¨..."
echo "==============================="

# 1. åœæ­¢ç°æœ‰æœåŠ¡
echo "ğŸ›‘ åœæ­¢ç°æœ‰æœåŠ¡..."
pkill -f uvicorn || true

# 2. å¤‡ä»½å½“å‰ä»£ç 
echo "ğŸ“¦ å¤‡ä»½å½“å‰ä»£ç ..."
if [ -d "backup_$(date +%Y%m%d_%H%M%S)" ]; then
    rm -rf backup_$(date +%Y%m%d_%H%M%S)
fi
cp -r . backup_$(date +%Y%m%d_%H%M%S)

# 3. æ£€æŸ¥å…³é”®æ–‡ä»¶
echo "ğŸ” æ£€æŸ¥å…³é”®æ–‡ä»¶..."
files_to_check=(
    "app.py"
    "services/ai_service_latest.py"
    "services/__init__.py"
    "test_latest_ai.py"
    "deploy_latest.sh"
    ".env"
)

for file in "${files_to_check[@]}"; do
    if [ -f "$file" ]; then
        echo "âœ… $file å­˜åœ¨"
    else
        echo "âŒ $file ä¸å­˜åœ¨"
    fi
done

# 4. æ£€æŸ¥servicesç›®å½•
echo ""
echo "ğŸ“ æ£€æŸ¥servicesç›®å½•..."
if [ -d "services" ]; then
    echo "servicesç›®å½•å­˜åœ¨ï¼ŒåŒ…å«æ–‡ä»¶ï¼š"
    ls -la services/
else
    echo "âŒ servicesç›®å½•ä¸å­˜åœ¨"
    mkdir -p services
fi

# 5. é‡æ–°åˆ›å»º__init__.py
echo ""
echo "ğŸ”§ ç¡®ä¿__init__.pyå­˜åœ¨..."
if [ ! -f "services/__init__.py" ]; then
    echo "# services package" > services/__init__.py
    echo "âœ… åˆ›å»ºservices/__init__.py"
else
    echo "âœ… services/__init__.pyå·²å­˜åœ¨"
fi

# 6. æ£€æŸ¥Pythonè·¯å¾„
echo ""
echo "ğŸ æ£€æŸ¥Pythonè·¯å¾„..."
python3 -c "import sys; print('Pythonè·¯å¾„:'); [print(p) for p in sys.path]"

# 7. æµ‹è¯•å¯¼å…¥
echo ""
echo "ğŸ§ª æµ‹è¯•æ¨¡å—å¯¼å…¥..."
python3 -c "
import sys
import os
sys.path.append(os.getcwd())
try:
    from services.ai_service_latest import AIService
    print('âœ… ai_service_latest å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ å¯¼å…¥å¤±è´¥: {e}')
    print('å½“å‰ç›®å½•:', os.getcwd())
    print('servicesç›®å½•å†…å®¹:', os.listdir('services') if os.path.exists('services') else 'ä¸å­˜åœ¨')
"

# 8. å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œé‡æ–°åˆ›å»ºæ–‡ä»¶
echo ""
echo "ğŸ“ å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œé‡æ–°åˆ›å»ºai_service_latest.py..."
if ! python3 -c "from services.ai_service_latest import AIService" 2>/dev/null; then
    echo "é‡æ–°åˆ›å»ºai_service_latest.py..."
    cat > services/ai_service_latest.py << 'EOF'
import os
import json
import asyncio
from typing import List, Dict, Any, Optional
import chromadb
from chromadb.config import Settings
import hashlib
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class AIService:
    def __init__(self):
        """åˆå§‹åŒ–AIæœåŠ¡"""
        self.api_key = os.getenv("AI_API_KEY", "sk-442562cd6b6b4b2896ebdac8ce8d047e")
        self.base_url = os.getenv("AI_API_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        self.model_name = os.getenv("AI_MODEL_NAME", "qwen-plus")
        self.embedding_model = os.getenv("AI_EMBEDDING_MODEL", "text-embedding-v3")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # åˆå§‹åŒ–ChromaDB
        self.chroma_client = chromadb.PersistentClient(
            path="./chroma_db",
            settings=Settings(anonymized_telemetry=False)
        )
        
        # è·å–æˆ–åˆ›å»ºé›†åˆ
        self.collection = self.chroma_client.get_or_create_collection(
            name="report_documents",
            metadata={"description": "å®è®­æŠ¥å‘Šæ–‡æ¡£å‘é‡å­˜å‚¨"}
        )
        
        print(f"AIæœåŠ¡åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {self.model_name}, Embeddingæ¨¡å‹: {self.embedding_model}")

    async def get_embeddings(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º"""
        try:
            # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬OpenAIå®¢æˆ·ç«¯è·å–embedding
            response = self.client.embeddings.create(
                input=[text],
                dimensions=1024,
                model=self.embedding_model,
                encoding_format="float"
            )
            
            embedding = response.data[0].embedding
            print(f"âœ… æˆåŠŸè·å–embeddingï¼Œç»´åº¦: {len(embedding)}")
            return embedding
            
        except Exception as e:
            print(f"âŒ Embedding APIè°ƒç”¨å¤±è´¥: {e}")
            # ä½¿ç”¨ç®€å•çš„å“ˆå¸Œä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            return self._fallback_embedding(text)

    def _fallback_embedding(self, text: str) -> List[float]:
        """å¤‡ç”¨embeddingæ–¹æ³•"""
        # ä½¿ç”¨ç®€å•çš„å“ˆå¸Œç”Ÿæˆ1024ç»´å‘é‡
        hash_obj = hashlib.sha256(text.encode())
        hash_hex = hash_obj.hexdigest()
        
        # å°†å“ˆå¸Œè½¬æ¢ä¸º1024ç»´å‘é‡
        embedding = []
        for i in range(1024):
            start = (i * 2) % len(hash_hex)
            end = start + 2
            if end > len(hash_hex):
                end = len(hash_hex)
            hex_part = hash_hex[start:end]
            if len(hex_part) < 2:
                hex_part = hex_part + "0" * (2 - len(hex_part))
            value = int(hex_part, 16) / 255.0  # å½’ä¸€åŒ–åˆ°0-1
            embedding.append(value)
        
        print(f"ä½¿ç”¨å¤‡ç”¨embeddingæ–¹æ³•ï¼Œç»´åº¦: {len(embedding)}")
        return embedding

    async def add_documents_to_vectorstore(self, documents: List[Dict[str, Any]]):
        """å°†æ–‡æ¡£æ·»åŠ åˆ°å‘é‡æ•°æ®åº“"""
        try:
            texts = [doc["content"] for doc in documents]
            metadatas = [{"source": doc["source"], "type": doc["type"]} for doc in documents]
            ids = [f"doc_{i}_{hash(doc['source'])}" for i, doc in enumerate(documents)]
            
            # è·å–æ‰€æœ‰æ–‡æ¡£çš„embeddings
            embeddings = []
            for text in texts:
                embedding = await self.get_embeddings(text)
                embeddings.append(embedding)
            
            # æ·»åŠ åˆ°ChromaDB
            self.collection.add(
                embeddings=embeddings,
                documents=texts,
                metadatas=metadatas,
                ids=ids
            )
            
            print(f"æˆåŠŸæ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“")
            
        except Exception as e:
            print(f"æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")

    async def search_similar_documents(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
        try:
            # è·å–æŸ¥è¯¢çš„embedding
            query_embeddings = await self.get_embeddings(query)
            
            # åœ¨ChromaDBä¸­æœç´¢
            results = self.collection.query(
                query_embeddings=query_embeddings,
                n_results=top_k
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            similar_docs = []
            if results["documents"] and results["documents"][0]:
                for i, doc in enumerate(results["documents"][0]):
                    similar_docs.append({
                        "content": doc,
                        "metadata": results["metadatas"][0][i] if results["metadatas"] and results["metadatas"][0] else {},
                        "distance": results["distances"][0][i] if results["distances"] and results["distances"][0] else 0
                    })
            
            return similar_docs
            
        except Exception as e:
            print(f"æœç´¢ç›¸ä¼¼æ–‡æ¡£å¤±è´¥: {e}")
            return []

    async def generate_report(self, query: str, context: List[str]) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        try:
            # æ„å»ºæç¤ºè¯
            prompt = self._build_prompt(query, context)
            
            # è°ƒç”¨APIç”ŸæˆæŠ¥å‘Š
            report = await self._call_qwen_api(prompt)
            
            return report
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯: {str(e)}"

    def _build_prompt(self, query: str, context: List[str]) -> str:
        """æ„å»ºæç¤ºè¯"""
        context_text = "\n\n".join(context)
        
        prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æŠ¥å‘Šï¼š

æŸ¥è¯¢é—®é¢˜ï¼š{query}

ç›¸å…³ä¿¡æ¯ï¼š
{context_text}

è¯·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. æ¦‚è¿°
2. è¯¦ç»†åˆ†æ
3. ç»“è®ºå’Œå»ºè®®

è¯·ç¡®ä¿æŠ¥å‘Šå†…å®¹å‡†ç¡®ã€è¯¦ç»†ä¸”æ˜“äºç†è§£ã€‚"""

        return prompt

    async def _call_qwen_api(self, prompt: str) -> str:
        """è°ƒç”¨åƒé—®APIç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        try:
            print(f"è°ƒç”¨åƒé—®APIç”ŸæˆæŠ¥å‘Š...")
            
            # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬OpenAIå®¢æˆ·ç«¯è°ƒç”¨èŠå¤©API
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=4000,
                top_p=0.9
            )
            
            content = response.choices[0].message.content
            print(f"âœ… æˆåŠŸç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼Œé•¿åº¦: {len(content)}")
            return content
            
        except Exception as e:
            print(f"âŒ åƒé—®APIè°ƒç”¨å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯: {str(e)}"

    async def clear_vectorstore(self):
        """æ¸…ç©ºå‘é‡æ•°æ®åº“"""
        try:
            self.chroma_client.delete_collection("report_documents")
            self.collection = self.chroma_client.create_collection(
                name="report_documents",
                metadata={"description": "å®è®­æŠ¥å‘Šæ–‡æ¡£å‘é‡å­˜å‚¨"}
            )
            print("å‘é‡æ•°æ®åº“å·²æ¸…ç©º")
        except Exception as e:
            print(f"æ¸…ç©ºå‘é‡æ•°æ®åº“å¤±è´¥: {e}")
EOF
    echo "âœ… ai_service_latest.py é‡æ–°åˆ›å»ºå®Œæˆ"
fi

# 9. å†æ¬¡æµ‹è¯•å¯¼å…¥
echo ""
echo "ğŸ§ª å†æ¬¡æµ‹è¯•æ¨¡å—å¯¼å…¥..."
python3 -c "
import sys
import os
sys.path.append(os.getcwd())
try:
    from services.ai_service_latest import AIService
    print('âœ… ai_service_latest å¯¼å…¥æˆåŠŸ')
except ImportError as e:
    print(f'âŒ å¯¼å…¥å¤±è´¥: {e}')
"

# 10. å¯åŠ¨æœåŠ¡
echo ""
echo "ğŸš€ å¯åŠ¨æœåŠ¡..."
nohup uvicorn app:app --host 0.0.0.0 --port 8000 --reload > logs/app.log 2>&1 &

# ç­‰å¾…å¯åŠ¨
sleep 5

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
if pgrep -f uvicorn > /dev/null; then
    echo "âœ… æœåŠ¡å¯åŠ¨æˆåŠŸ"
    echo "ğŸŒ è®¿é—®åœ°å€: http://47.109.24.229:8000"
else
    echo "âŒ æœåŠ¡å¯åŠ¨å¤±è´¥ï¼ŒæŸ¥çœ‹æ—¥å¿—:"
    tail -n 10 logs/app.log
fi

echo ""
echo "ğŸ“ æŸ¥çœ‹å®æ—¶æ—¥å¿—:"
echo "tail -f logs/app.log" 