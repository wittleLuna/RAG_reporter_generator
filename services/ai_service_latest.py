import os
import json
import asyncio
from typing import List, Dict, Any, Optional
import chromadb
from chromadb.config import Settings
import hashlib
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class AIService:
    def __init__(self):
        """åˆå§‹åŒ–AIæœåŠ¡"""
        self.api_key = os.getenv("AI_API_KEY", "sk-442562cd6b6b4b2896ebdac8ce8d047e")
        self.base_url = os.getenv("AI_API_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        self.model_name = os.getenv("AI_MODEL_NAME", "qwen-plus")
        self.embedding_model = os.getenv("AI_EMBEDDING_MODEL", "text-embedding-v3")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # åˆå§‹åŒ–ChromaDB
        self.chroma_client = chromadb.PersistentClient(
            path="./chroma_db",
            settings=Settings(anonymized_telemetry=False)
        )
        
        # è·å–æˆ–åˆ›å»ºé›†åˆ
        self.collection = self.chroma_client.get_or_create_collection(
            name="report_documents",
            metadata={"description": "å®è®­æŠ¥å‘Šæ–‡æ¡£å‘é‡å­˜å‚¨"}
        )
        
        print(f"AIæœåŠ¡åˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {self.model_name}, Embeddingæ¨¡å‹: {self.embedding_model}")

    async def get_embeddings(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º"""
        try:
            # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬OpenAIå®¢æˆ·ç«¯è·å–embedding
            response = self.client.embeddings.create(
                input=[text],
                dimensions=1024,
                model=self.embedding_model,
                encoding_format="float"
            )
            
            embedding = response.data[0].embedding
            print(f"âœ… æˆåŠŸè·å–embeddingï¼Œç»´åº¦: {len(embedding)}")
            return embedding
            
        except Exception as e:
            print(f"âŒ Embedding APIè°ƒç”¨å¤±è´¥: {e}")
            # ä½¿ç”¨ç®€å•çš„å“ˆå¸Œä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
            return self._fallback_embedding(text)

    def _fallback_embedding(self, text: str) -> List[float]:
        """å¤‡ç”¨embeddingæ–¹æ³•"""
        # ä½¿ç”¨ç®€å•çš„å“ˆå¸Œç”Ÿæˆ1024ç»´å‘é‡
        hash_obj = hashlib.sha256(text.encode())
        hash_hex = hash_obj.hexdigest()
        
        # å°†å“ˆå¸Œè½¬æ¢ä¸º1024ç»´å‘é‡
        embedding = []
        for i in range(1024):
            start = (i * 2) % len(hash_hex)
            end = start + 2
            if end > len(hash_hex):
                end = len(hash_hex)
            hex_part = hash_hex[start:end]
            if len(hex_part) < 2:
                hex_part = hex_part + "0" * (2 - len(hex_part))
            value = int(hex_part, 16) / 255.0  # å½’ä¸€åŒ–åˆ°0-1
            embedding.append(value)
        
        print(f"ä½¿ç”¨å¤‡ç”¨embeddingæ–¹æ³•ï¼Œç»´åº¦: {len(embedding)}")
        return embedding

    async def add_documents_to_vectorstore(self, documents: List[Dict[str, Any]]):
        """å°†æ–‡æ¡£æ·»åŠ åˆ°å‘é‡æ•°æ®åº“"""
        try:
            texts = [doc["content"] for doc in documents]
            metadatas = [{"source": doc["source"], "type": doc["type"]} for doc in documents]
            ids = [f"doc_{i}_{hash(doc['source'])}" for i, doc in enumerate(documents)]
            
            # è·å–æ‰€æœ‰æ–‡æ¡£çš„embeddings
            embeddings = []
            for text in texts:
                embedding = await self.get_embeddings(text)
                embeddings.append(embedding)
            
            # æ·»åŠ åˆ°ChromaDB
            self.collection.add(
                embeddings=embeddings,
                documents=texts,
                metadatas=metadatas,
                ids=ids
            )
            
            print(f"æˆåŠŸæ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“")
            
        except Exception as e:
            print(f"æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")

    async def search_similar_documents(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
        try:
            # è·å–æŸ¥è¯¢çš„embedding
            query_embeddings = await self.get_embeddings(query)
            
            # åœ¨ChromaDBä¸­æœç´¢
            results = self.collection.query(
                query_embeddings=query_embeddings,
                n_results=top_k
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            similar_docs = []
            if results["documents"] and results["documents"][0]:
                for i, doc in enumerate(results["documents"][0]):
                    similar_docs.append({
                        "content": doc,
                        "metadata": results["metadatas"][0][i] if results["metadatas"] and results["metadatas"][0] else {},
                        "distance": results["distances"][0][i] if results["distances"] and results["distances"][0] else 0
                    })
            
            return similar_docs
            
        except Exception as e:
            print(f"æœç´¢ç›¸ä¼¼æ–‡æ¡£å¤±è´¥: {e}")
            return []

    async def generate_report_with_prompt(self, query: str, custom_prompt: str, target_pages: int = None) -> str:
        """ä½¿ç”¨è‡ªå®šä¹‰Promptç”ŸæˆæŠ¥å‘Š"""
        try:
            # æ ¹æ®ç›®æ ‡é¡µæ•°è°ƒæ•´max_tokens
            if target_pages and target_pages > 0:
                # ä¼°ç®—æ¯ä¸ªé¡µé¢çš„tokenæ•°ï¼ˆä¸­æ–‡çº¦1.5å­—ç¬¦=1tokenï¼‰
                if target_pages <= 3:
                    max_tokens = 2000
                elif target_pages <= 6:
                    max_tokens = 4000
                elif target_pages <= 10:
                    max_tokens = 8000
                elif target_pages <= 15:
                    max_tokens = 8192  # é™åˆ¶æœ€å¤§å€¼
                else:
                    max_tokens = 8192
            else:
                max_tokens = 4000
            max_tokens = min(max_tokens, 8192)  # å†æ¬¡ä¿é™©
            print(f"ğŸ“„ ç›®æ ‡é¡µæ•°: {target_pages or 'è‡ªåŠ¨'}, è®¾ç½®max_tokens: {max_tokens}")
            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„è‡ªå®šä¹‰Promptè°ƒç”¨API
            report = await self._call_qwen_api(custom_prompt, max_tokens)
            return report
        except Exception as e:
            print(f"âŒ ä½¿ç”¨è‡ªå®šä¹‰Promptç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯: {str(e)}"

    async def generate_report(self, query: str, context: List[str]) -> str:
        """ç”ŸæˆæŠ¥å‘Šï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        try:
            # æ„å»ºæç¤ºè¯
            prompt = self._build_prompt(query, context)
            
            # è°ƒç”¨APIç”ŸæˆæŠ¥å‘Š
            report = await self._call_qwen_api(prompt)
            
            return report
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯: {str(e)}"

    def _build_prompt(self, query: str, context: List[str]) -> str:
        """æ„å»ºæç¤ºè¯"""
        context_text = "\n\n".join(context)
        
        prompt = f"""ä½ æ˜¯ä¸€ä½å®è®­æŠ¥å‘Šè‡ªåŠ¨ç”ŸæˆåŠ©æ‰‹ï¼Œä»»åŠ¡æ˜¯å°†ä»¥ä¸‹èµ„æ–™æ•´åˆä¸ºä¸€ç¯‡ç»“æ„æ¸…æ™°ã€è¯­è¨€é€šé¡ºã€æ ¼å¼ä¸¥æ ¼çš„ Markdown æŠ¥å‘Šã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¦æ±‚ç”Ÿæˆå†…å®¹ï¼š

ã€æ ¼å¼è§„åˆ™ã€‘ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š
1. åªå…è®¸ä½¿ç”¨ä»¥ä¸‹ Markdown ç¬¦å·ï¼š`#`ï¼ˆä¸€çº§æ ‡é¢˜ï¼‰ã€`##`ï¼ˆäºŒçº§æ ‡é¢˜ï¼‰ã€`###`ï¼ˆä¸‰çº§æ ‡é¢˜ï¼‰ã€```ï¼ˆä»£ç å—ï¼‰ã€`-`ï¼ˆç”¨äºéç¼–å·åˆ—è¡¨ï¼‰ã€‚
2. ç¦æ­¢ä½¿ç”¨ä»¥ä¸‹å†…å®¹ï¼š
   - ç¦æ­¢ä½¿ç”¨ `---` åˆ†å‰²æ®µè½ï¼ˆåœ¨æ¯ä¸ªæ®µè½çš„æœ€åï¼‰ï¼›
   - ç¦æ­¢ä½¿ç”¨ `#####`åŠä»¥åçš„æ ‡é¢˜ï¼›
   - ç¦æ­¢ä½¿ç”¨ HTML æ ‡ç­¾ï¼ˆå¦‚ `<p>`ã€`<br>`ï¼‰ï¼›
   - ç¦æ­¢å†™"å¸Œæœ›æœ¬æŠ¥å‘Šå¯¹ä½ æœ‰æ‰€å¸®åŠ©"ç­‰å®¢å¥—è¯ã€‚
   - ç¦æ­¢åœ¨æŠ¥å‘Šæ ‡é¢˜ä½¿ç”¨å¦‚"å®è®­æŠ¥å‘Šï¼šxxx"çš„æ ¼å¼ï¼Œç›´æ¥å†™æŠ¥å‘Šå
   - ç¦æ­¢å‡ºç°ï¼š' â€¢ **æ–‡æœ¬å†…å®¹** ' çš„æ ¼å¼, 'â€¢' å’Œ **xxx** åªèƒ½å•ç‹¬å‡ºç°
3. æ®µè½ç¼–å·è¯·ä½¿ç”¨ `1.`ã€`2.`ã€`3.` çš„æ–¹å¼ï¼Œ**ä¸è¦ä½¿ç”¨ `-` å’Œ 'â€¢' ä½œä¸ºç¼–å·åˆ—è¡¨**ã€‚
4. **å›¾ç‰‡æ’å…¥æ ¼å¼ä¸ºï¼š`{{image:img_x}}`ï¼Œå¦‚ï¼š`{{image:img_1}}`ï¼Œå¿…é¡»å‡ºç°åœ¨å†…å®¹åˆé€‚ä½ç½®**ã€‚
5. æ‰€æœ‰ä»£ç å¿…é¡»ä½¿ç”¨æˆå¯¹çš„ ``` åŒ…è£¹ï¼Œå¹¶ä¿æŒåŸå§‹ç¼©è¿›ã€‚
6. é™¤ç‰¹æ®Šè¯´æ˜å¤–ï¼Œè¯·ä¿æŒè¯­æ°”æ­£å¼ã€ä¸­æ€§ã€ä¿¡æ¯å¯¼å‘ã€‚
7. åœ¨å‚è€ƒèµ„æ–™çš„åŸºç¡€ä¸Šæ‹“å±•å†…å®¹ï¼Œä¸°å¯ŒæŠ¥å‘Šçš„å†…å®¹

ã€ä»»åŠ¡è¯´æ˜ã€‘ï¼š
è¯·æ ¹æ®ä»¥ä¸‹æŸ¥è¯¢å’Œèµ„æ–™å†…å®¹ï¼Œæ•´åˆæ’°å†™å®è®­æŠ¥å‘Šï¼š

æŸ¥è¯¢é—®é¢˜ï¼š
{query}

ç›¸å…³èµ„æ–™ï¼ˆä¾›å‚è€ƒï¼‰ï¼š
{context_text}

è¯·æ ¹æ®å†…å®¹æ’°å†™åŒ…å«ä»¥ä¸‹éƒ¨åˆ†çš„æŠ¥å‘Šï¼š
1. æ¦‚è¿°
2. è¯¦ç»†åˆ†æï¼ˆå¯ä»¥å¤šå°èŠ‚ï¼‰
3. ç»“è®ºä¸å»ºè®®
4. å¦‚æœ‰å¿…è¦ï¼Œå¯å¢åŠ æŠ€æœ¯è¿‡ç¨‹ã€å›¾ç¤ºæè¿°ç­‰è¡¥å……éƒ¨åˆ†

æœ€ç»ˆè¯·è¾“å‡ºä¸€æ®µ**ç»“æ„è‰¯å¥½ã€æ ¼å¼å‡†ç¡®ã€å†…å®¹ä¸¥è°¨çš„ Markdown æŠ¥å‘Š**ï¼Œæ— éœ€è¯´æ˜"æŠ¥å‘Šç»“æŸ"ç­‰è¯­å¥ã€‚"""

        return prompt

    async def _call_qwen_api(self, prompt: str, max_tokens: int) -> str:
        """è°ƒç”¨åƒé—®APIç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        try:
            print(f"è°ƒç”¨åƒé—®APIç”ŸæˆæŠ¥å‘Š...")
            
            # ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬OpenAIå®¢æˆ·ç«¯è°ƒç”¨èŠå¤©API
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=max_tokens,
                top_p=0.9
            )
            
            content = response.choices[0].message.content
            print(f"âœ… æˆåŠŸç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼Œé•¿åº¦: {len(content)}")
            return content
            
        except Exception as e:
            print(f"âŒ åƒé—®APIè°ƒç”¨å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œç”ŸæˆæŠ¥å‘Šæ—¶å‡ºç°é”™è¯¯: {str(e)}"

    async def clear_vectorstore(self):
        """æ¸…ç©ºå‘é‡æ•°æ®åº“"""
        try:
            self.chroma_client.delete_collection("report_documents")
            self.collection = self.chroma_client.create_collection(
                name="report_documents",
                metadata={"description": "å®è®­æŠ¥å‘Šæ–‡æ¡£å‘é‡å­˜å‚¨"}
            )
            print("å‘é‡æ•°æ®åº“å·²æ¸…ç©º")
        except Exception as e:
            print(f"æ¸…ç©ºå‘é‡æ•°æ®åº“å¤±è´¥: {e}") 